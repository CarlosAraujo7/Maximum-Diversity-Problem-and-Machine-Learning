{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando e otimizando modelo: RandomForest\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Melhores hiperparâmetros para RandomForest: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "Treinando e otimizando modelo: LogisticRegression\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Melhores hiperparâmetros para LogisticRegression: {'C': 0.01}\n",
      "Treinando e otimizando modelo: KNN\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Melhores hiperparâmetros para KNN: {'metric': 'euclidean', 'n_neighbors': 7}\n",
      "Treinando e otimizando modelo: DecisionTree\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Melhores hiperparâmetros para DecisionTree: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1}\n",
      "Avaliação do modelo: RandomForest\n",
      "Avaliação do modelo: LogisticRegression\n",
      "Avaliação do modelo: KNN\n",
      "Avaliação do modelo: DecisionTree\n",
      "Resultados do modelo RandomForest salvos em '../Main/Resultados Modelos Matriz/resultados_treinamento_RandomForest.csv'.\n",
      "Resultados do modelo LogisticRegression salvos em '../Main/Resultados Modelos Matriz/resultados_treinamento_LogisticRegression.csv'.\n",
      "Resultados do modelo KNN salvos em '../Main/Resultados Modelos Matriz/resultados_treinamento_KNN.csv'.\n",
      "Resultados do modelo DecisionTree salvos em '../Main/Resultados Modelos Matriz/resultados_treinamento_DecisionTree.csv'.\n",
      "Resultados consolidados salvos em '../Main/Resultados Modelos Matriz/resultados_consolidados.csv'.\n",
      "\n",
      "Resultados do modelo: RandomForest\n",
      "                                           Instância  Classe Precisão Recall  \\\n",
      "0  MDG-a_15_n500_m50_matriz_adjacencia_caracteris...       1     0.90   0.90   \n",
      "1  MDG-a_15_n500_m50_matriz_adjacencia_caracteris...       2     0.10   0.10   \n",
      "2  MDG-a_16_n500_m50_matriz_adjacencia_caracteris...       1     0.91   0.91   \n",
      "3  MDG-a_16_n500_m50_matriz_adjacencia_caracteris...       2     0.18   0.18   \n",
      "4  MDG-a_17_n500_m50_matriz_adjacencia_caracteris...       1     0.91   0.91   \n",
      "\n",
      "  F1-Score  Suporte                                  Vértices Classe 2  \n",
      "0     0.90    450.0                                               None  \n",
      "1     0.10     50.0  [1, 6, 38, 43, 63, 67, 74, 75, 122, 125, 130, ...  \n",
      "2     0.91    450.0                                               None  \n",
      "3     0.18     50.0  [1, 9, 15, 18, 42, 44, 51, 67, 71, 78, 97, 108...  \n",
      "4     0.91    450.0                                               None  \n",
      "\n",
      "Resultados do modelo: LogisticRegression\n",
      "                                           Instância  Classe Precisão Recall  \\\n",
      "0  MDG-a_15_n500_m50_matriz_adjacencia_caracteris...       1     0.91   0.91   \n",
      "1  MDG-a_15_n500_m50_matriz_adjacencia_caracteris...       2     0.18   0.18   \n",
      "2  MDG-a_16_n500_m50_matriz_adjacencia_caracteris...       1     0.90   0.90   \n",
      "3  MDG-a_16_n500_m50_matriz_adjacencia_caracteris...       2     0.08   0.08   \n",
      "4  MDG-a_17_n500_m50_matriz_adjacencia_caracteris...       1     0.90   0.90   \n",
      "\n",
      "  F1-Score  Suporte                                  Vértices Classe 2  \n",
      "0     0.91    450.0                                               None  \n",
      "1     0.18     50.0  [1, 10, 11, 16, 20, 22, 24, 25, 35, 38, 40, 50...  \n",
      "2     0.90    450.0                                               None  \n",
      "3     0.08     50.0  [2, 6, 11, 18, 20, 25, 31, 35, 37, 42, 45, 51,...  \n",
      "4     0.90    450.0                                               None  \n",
      "\n",
      "Resultados do modelo: KNN\n",
      "                                           Instância  Classe Precisão Recall  \\\n",
      "0  MDG-a_15_n500_m50_matriz_adjacencia_caracteris...       1     0.91   0.91   \n",
      "1  MDG-a_15_n500_m50_matriz_adjacencia_caracteris...       2     0.20   0.20   \n",
      "2  MDG-a_16_n500_m50_matriz_adjacencia_caracteris...       1     0.90   0.90   \n",
      "3  MDG-a_16_n500_m50_matriz_adjacencia_caracteris...       2     0.14   0.14   \n",
      "4  MDG-a_17_n500_m50_matriz_adjacencia_caracteris...       1     0.91   0.91   \n",
      "\n",
      "  F1-Score  Suporte                                  Vértices Classe 2  \n",
      "0     0.91    450.0                                               None  \n",
      "1     0.20     50.0  [23, 59, 86, 93, 94, 101, 105, 114, 117, 119, ...  \n",
      "2     0.90    450.0                                               None  \n",
      "3     0.14     50.0  [0, 1, 5, 10, 14, 15, 17, 26, 27, 31, 34, 42, ...  \n",
      "4     0.91    450.0                                               None  \n",
      "\n",
      "Resultados do modelo: DecisionTree\n",
      "                                           Instância  Classe Precisão Recall  \\\n",
      "0  MDG-a_15_n500_m50_matriz_adjacencia_caracteris...       1     0.90   0.90   \n",
      "1  MDG-a_15_n500_m50_matriz_adjacencia_caracteris...       2     0.14   0.14   \n",
      "2  MDG-a_16_n500_m50_matriz_adjacencia_caracteris...       1     0.91   0.91   \n",
      "3  MDG-a_16_n500_m50_matriz_adjacencia_caracteris...       2     0.18   0.18   \n",
      "4  MDG-a_17_n500_m50_matriz_adjacencia_caracteris...       1     0.90   0.90   \n",
      "\n",
      "  F1-Score  Suporte                                  Vértices Classe 2  \n",
      "0     0.90    450.0                                               None  \n",
      "1     0.14     50.0  [3, 6, 7, 19, 21, 22, 43, 45, 50, 56, 57, 58, ...  \n",
      "2     0.91    450.0                                               None  \n",
      "3     0.18     50.0  [3, 51, 61, 67, 71, 75, 77, 87, 88, 99, 251, 2...  \n",
      "4     0.90    450.0                                               None  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Caminho para o diretório onde estão os arquivos\n",
    "caminho = \"../Main/Instances Matriz\"  # Atualizado conforme solicitado\n",
    "\n",
    "def carregar_dataframes(caminho):\n",
    "    \"\"\"\n",
    "    Carrega todos os arquivos CSV do diretório especificado.\n",
    "\n",
    "    Args:\n",
    "        caminho (str): Caminho para o diretório contendo os arquivos CSV.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário com nomes dos arquivos como chaves e DataFrames como valores.\n",
    "    \"\"\"\n",
    "    arquivos = [os.path.join(caminho, f) for f in os.listdir(caminho) if f.endswith(\".csv\")]\n",
    "    if not arquivos:\n",
    "        raise ValueError(\"Nenhum arquivo CSV encontrado no diretório especificado.\")\n",
    "    \n",
    "    dataframes = {}\n",
    "    for arquivo in arquivos:\n",
    "        nome = os.path.basename(arquivo).split(\".\")[0]  # Nome do arquivo sem extensão\n",
    "        try:\n",
    "            df = pd.read_csv(arquivo)\n",
    "            dataframes[nome] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {arquivo}: {e}\")\n",
    "    return dataframes\n",
    "\n",
    "def coletar_todas_colunas(dataframes):\n",
    "    \"\"\"\n",
    "    Coleta todas as colunas únicas de todos os DataFrames.\n",
    "\n",
    "    Args:\n",
    "        dataframes (dict): Dicionário de DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista ordenada de todas as colunas únicas.\n",
    "    \"\"\"\n",
    "    todas_colunas = set()\n",
    "    for df in dataframes.values():\n",
    "        todas_colunas.update(df.columns)\n",
    "    return sorted(todas_colunas)\n",
    "\n",
    "def padronizar_colunas(df, todas_colunas):\n",
    "    \"\"\"\n",
    "    Padroniza as colunas de um DataFrame, adicionando colunas ausentes com valor 0.0.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame a ser padronizado.\n",
    "        todas_colunas (list): Lista de todas as colunas únicas.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame padronizado.\n",
    "    \"\"\"\n",
    "    colunas_ausentes = [col for col in todas_colunas if col not in df.columns]\n",
    "    if colunas_ausentes:\n",
    "        colunas_ausentes_df = pd.DataFrame(0.0, index=df.index, columns=colunas_ausentes)\n",
    "        df = pd.concat([df, colunas_ausentes_df], axis=1)\n",
    "    return df[todas_colunas]\n",
    "\n",
    "def carregar_e_padronizar_dataframes(caminho):\n",
    "    \"\"\"\n",
    "    Carrega e padroniza todos os DataFrames do diretório especificado.\n",
    "\n",
    "    Args:\n",
    "        caminho (str): Caminho para o diretório contendo os arquivos CSV.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Dicionário de DataFrames padronizados e a lista de todas as colunas.\n",
    "    \"\"\"\n",
    "    dataframes = carregar_dataframes(caminho)\n",
    "    todas_colunas = coletar_todas_colunas(dataframes)\n",
    "    dataframes_padronizados = {nome: padronizar_colunas(df, todas_colunas) for nome, df in dataframes.items()}\n",
    "    return dataframes_padronizados, todas_colunas\n",
    "\n",
    "def preparar_dados(dataframes_padronizados, todas_colunas, num_train=30):\n",
    "    \"\"\"\n",
    "    Separa os DataFrames em conjuntos de treinamento e teste.\n",
    "\n",
    "    Args:\n",
    "        dataframes_padronizados (dict): Dicionário de DataFrames padronizados.\n",
    "        todas_colunas (list): Lista de todas as colunas únicas.\n",
    "        num_train (int): Número de DataFrames para treinamento.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Dados de treinamento, rótulos de treinamento, dados de teste e colunas de vértices.\n",
    "    \"\"\"\n",
    "    dataframes_items = list(dataframes_padronizados.items())\n",
    "    train_data = dict(dataframes_items[:num_train])\n",
    "    test_data = dict(dataframes_items[num_train:])\n",
    "    \n",
    "    if not train_data:\n",
    "        raise ValueError(\"Nenhum DataFrame disponível para treinamento.\")\n",
    "    if not test_data:\n",
    "        raise ValueError(\"Nenhum DataFrame disponível para teste.\")\n",
    "    \n",
    "    # Identificar colunas de vértices (assumindo que 'Conjuntos' é a coluna alvo)\n",
    "    colunas_vertices = [col for col in todas_colunas if col != \"Conjuntos\"]\n",
    "    \n",
    "    # Concatenar DataFrames de treinamento\n",
    "    train_df = pd.concat(train_data.values(), ignore_index=True)\n",
    "    X_train = train_df[colunas_vertices].copy()\n",
    "    y_train = train_df[\"Conjuntos\"].astype(int)\n",
    "    \n",
    "    return X_train, y_train, test_data, colunas_vertices\n",
    "\n",
    "def treinar_modelos(X_train, y_train, usar_pca=True):\n",
    "    \"\"\"\n",
    "    Normaliza, balanceia, aplica PCA e treina múltiplos modelos com otimização de hiperparâmetros.\n",
    "\n",
    "    Args:\n",
    "        X_train (DataFrame): Dados de treinamento.\n",
    "        y_train (Series): Rótulos de treinamento.\n",
    "        usar_pca (bool): Se deve aplicar PCA.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário contendo scaler, PCA (se usado) e modelos treinados.\n",
    "    \"\"\"\n",
    "    # Normalizar os dados\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Tratar desbalanceamento com SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "    # Aplicar PCA opcionalmente\n",
    "    if usar_pca:\n",
    "        pca = PCA(n_components=0.95, random_state=42)\n",
    "        X_train_bal = pca.fit_transform(X_train_bal)\n",
    "    else:\n",
    "        pca = None\n",
    "    \n",
    "    # Ajustar pesos das classes\n",
    "    classes = np.array([1, 2])\n",
    "    pesos = compute_class_weight('balanced', classes=classes, y=y_train_bal)\n",
    "    class_weight_dict = {1: pesos[0], 2: pesos[1]}\n",
    "    \n",
    "    # Dicionário para armazenar os modelos treinados\n",
    "    modelos_treinados = {}\n",
    "\n",
    "    # Otimização para cada modelo\n",
    "    modelos_com_parametros = {\n",
    "        \"RandomForest\": (RandomForestClassifier(random_state=42, class_weight=class_weight_dict), {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }),\n",
    "        \"LogisticRegression\": (LogisticRegression(random_state=42, class_weight=class_weight_dict, max_iter=1000), {\n",
    "            'C': [0.01, 0.1, 1, 10]\n",
    "        }),\n",
    "        #\"SVM\": (SVC(probability=True, random_state=42), {\n",
    "            #'C': [0.1, 1, 10],\n",
    "            #'kernel': ['linear', 'poly', 'rbf'],\n",
    "            #'gamma': ['scale', 'auto']\n",
    "        #}),\n",
    "        \"KNN\": (KNeighborsClassifier(), {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "        }),\n",
    "        \"DecisionTree\": (DecisionTreeClassifier(random_state=42, class_weight=class_weight_dict), {\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        })\n",
    "    }\n",
    "\n",
    "    # Treinamento com otimização de hiperparâmetros\n",
    "    for nome, (modelo, parametros) in modelos_com_parametros.items():\n",
    "        print(f\"Treinando e otimizando modelo: {nome}\")\n",
    "        grid_search = GridSearchCV(\n",
    "            modelo, parametros, cv=3, scoring='f1', n_jobs=-1, verbose=2\n",
    "        )\n",
    "        grid_search.fit(X_train_bal, y_train_bal)\n",
    "        modelos_treinados[nome] = grid_search.best_estimator_\n",
    "        print(f\"Melhores hiperparâmetros para {nome}: {grid_search.best_params_}\")\n",
    "    \n",
    "    return scaler, pca, modelos_treinados\n",
    "\n",
    "def avaliar_modelos(modelos_treinados, scaler, pca, test_data, todas_colunas, colunas_vertices):\n",
    "    \"\"\"\n",
    "    Avalia múltiplos modelos nos dados de teste e coleta os vértices da classe 2.\n",
    "\n",
    "    Args:\n",
    "        modelos_treinados (dict): Dicionário de modelos treinados.\n",
    "        scaler (StandardScaler): Objeto scaler treinado.\n",
    "        pca (PCA): Objeto PCA treinado ou None.\n",
    "        test_data (dict): Dicionário de DataFrames de teste.\n",
    "        todas_colunas (list): Lista de todas as colunas únicas.\n",
    "        colunas_vertices (list): Lista de colunas de vértices.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário de DataFrames contendo os resultados para cada modelo.\n",
    "    \"\"\"\n",
    "    resultados_modelos = {nome: [] for nome in modelos_treinados.keys()}\n",
    "    \n",
    "    for nome_modelo, modelo in modelos_treinados.items():\n",
    "        print(f\"Avaliação do modelo: {nome_modelo}\")\n",
    "        resultados_detalhados = []\n",
    "        for nome_instancia, df in test_data.items():\n",
    "            # Preparar dados de teste\n",
    "            X_test = df[colunas_vertices].copy()\n",
    "            y_test = df[\"Conjuntos\"].astype(int)\n",
    "            \n",
    "            # Normalizar e aplicar PCA opcionalmente\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            if pca:\n",
    "                X_test_scaled = pca.transform(X_test_scaled)\n",
    "            \n",
    "            # Predição e obtenção de probabilidades\n",
    "            y_pred = modelo.predict(X_test_scaled)\n",
    "            y_proba = modelo.predict_proba(X_test_scaled)\n",
    "            \n",
    "            # Determinar o número de vértices da diversidade máxima pela instância\n",
    "            # Assumindo o padrão 'SOM-a_24_n100_m10_matriz_adjacencia_caracteristicas'\n",
    "            # onde 'm10' indica m = 10\n",
    "            try:\n",
    "                m_part = [part for part in nome_instancia.split(\"_\") if part.startswith(\"m\")][0]\n",
    "                num_vertices_needed = int(m_part[1:])\n",
    "            except (IndexError, ValueError):\n",
    "                print(f\"Erro ao extrair 'm' de {nome_instancia}. Definindo num_vertices_needed=0.\")\n",
    "                num_vertices_needed = 0\n",
    "            \n",
    "            # Garantir que num_vertices_needed não exceda o número total de vértices\n",
    "            total_vertices = len(colunas_vertices)\n",
    "            if num_vertices_needed > total_vertices:\n",
    "                print(f\"Warning: 'm' ({num_vertices_needed}) excede o número total de vértices ({total_vertices}). Ajustando 'm' para {total_vertices}.\")\n",
    "                num_vertices_needed = total_vertices\n",
    "            \n",
    "            # Ajustar as predições pelo ranqueamento corrigido\n",
    "            y_pred_adjusted = rank_and_adjust_corrected(y_pred, y_proba, num_vertices_needed)\n",
    "            \n",
    "            # Verificação para garantir o número correto de classe 2\n",
    "            num_class_2 = np.sum(y_pred_adjusted == 2)\n",
    "            if num_class_2 != num_vertices_needed:\n",
    "                print(f\"Erro: Para {nome_instancia}, esperado {num_vertices_needed} vértices na classe 2, mas encontrado {num_class_2}.\")\n",
    "                # Opcionalmente, você pode decidir como lidar com esse caso\n",
    "            \n",
    "            # Relatório de métricas detalhado\n",
    "            relatorio = classification_report(y_test, y_pred_adjusted, output_dict=True, zero_division=0)\n",
    "            \n",
    "            # Obter a lista de vértices na classe 2\n",
    "            vertices_classe_2 = df.iloc[y_pred_adjusted == 2]\n",
    "            vertices_lista = vertices_classe_2.index.tolist() if not vertices_classe_2.empty else []\n",
    "            \n",
    "            # Adicionar resultados para cada classe\n",
    "            for classe in [1, 2]:\n",
    "                if str(classe) in relatorio:\n",
    "                    resultados_modelos[nome_modelo].append({\n",
    "                        \"Instância\": nome_instancia,\n",
    "                        \"Classe\": classe,\n",
    "                        \"Precisão\": f\"{relatorio[str(classe)]['precision']:.2f}\" if not np.isnan(relatorio[str(classe)]['precision']) else \"0.00\",\n",
    "                        \"Recall\": f\"{relatorio[str(classe)]['recall']:.2f}\" if not np.isnan(relatorio[str(classe)]['recall']) else \"0.00\",\n",
    "                        \"F1-Score\": f\"{relatorio[str(classe)]['f1-score']:.2f}\" if not np.isnan(relatorio[str(classe)]['f1-score']) else \"0.00\",\n",
    "                        \"Suporte\": relatorio[str(classe)]['support'],\n",
    "                        \"Vértices Classe 2\": vertices_lista if classe == 2 else None,\n",
    "                    })\n",
    "        \n",
    "        # Converter resultados detalhados para DataFrame\n",
    "        resultados_detalhados_df = pd.DataFrame(resultados_modelos[nome_modelo])\n",
    "        \n",
    "        # Reorganizar colunas para melhor visualização\n",
    "        colunas_order = [\"Instância\", \"Classe\", \"Precisão\", \"Recall\", \"F1-Score\", \"Suporte\", \"Vértices Classe 2\"]\n",
    "        resultados_detalhados_df = resultados_detalhados_df[colunas_order]\n",
    "        \n",
    "        resultados_modelos[nome_modelo] = resultados_detalhados_df\n",
    "    \n",
    "    return resultados_modelos\n",
    "\n",
    "def rank_and_adjust_corrected(y_pred, y_proba, num_vertices_needed):\n",
    "    \"\"\"\n",
    "    Ajusta as predições para garantir que exatamente num_vertices_needed instâncias sejam classificadas como classe 2.\n",
    "    Isso pode ser feito selecionando as instâncias com as maiores probabilidades de classe 2.\n",
    "\n",
    "    Args:\n",
    "        y_pred (np.array): Predições originais do modelo.\n",
    "        y_proba (np.array): Probabilidades das classes.\n",
    "        num_vertices_needed (int): Número de instâncias que devem ser classificadas como classe 2.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Predições ajustadas.\n",
    "    \"\"\"\n",
    "    if num_vertices_needed == 0:\n",
    "        return y_pred  # Sem ajuste necessário\n",
    "    \n",
    "    # Obter as probabilidades de classe 2\n",
    "    proba_class_2 = y_proba[:, 1]\n",
    "    \n",
    "    # Obter os índices ordenados pelas maiores probabilidades de classe 2\n",
    "    sorted_indices = np.argsort(proba_class_2)[::-1]\n",
    "    \n",
    "    # Inicializar predições ajustadas com as predições originais\n",
    "    y_pred_adjusted = y_pred.copy()\n",
    "    \n",
    "    # Definir as primeiras num_vertices_needed instâncias como classe 2\n",
    "    y_pred_adjusted[sorted_indices[:num_vertices_needed]] = 2\n",
    "    \n",
    "    # Garantir que apenas num_vertices_needed instâncias sejam classe 2\n",
    "    y_pred_adjusted[y_pred_adjusted == 2] = 1  # Temporariamente\n",
    "    y_pred_adjusted[sorted_indices[:num_vertices_needed]] = 2\n",
    "    \n",
    "    return y_pred_adjusted\n",
    "\n",
    "def salvar_resultados(resultados_modelos):\n",
    "    \"\"\"\n",
    "    Salva os resultados de cada modelo em arquivos CSV separados.\n",
    "\n",
    "    Args:\n",
    "        resultados_modelos (dict): Dicionário de DataFrames contendo os resultados para cada modelo.\n",
    "    \"\"\"\n",
    "    for nome_modelo, df in resultados_modelos.items():\n",
    "        nome_arquivo = f\"../Main/Resultados Modelos Matriz/resultados_treinamento_{nome_modelo}.csv\"\n",
    "        df.to_csv(nome_arquivo, index=False, float_format='%.2f')\n",
    "        print(f\"Resultados do modelo {nome_modelo} salvos em '{nome_arquivo}'.\")\n",
    "\n",
    "def salvar_resultados_consolidados(resultados_modelos, caminho_saida=\"../Main/Resultados Modelos Matriz/resultados_consolidados.csv\"):\n",
    "    \"\"\"\n",
    "    Salva os resultados de todos os modelos em um único arquivo CSV com uma coluna indicando o modelo.\n",
    "\n",
    "    Args:\n",
    "        resultados_modelos (dict): Dicionário de DataFrames contendo os resultados para cada modelo.\n",
    "        caminho_saida (str): Caminho para salvar o arquivo CSV consolidado.\n",
    "    \"\"\"\n",
    "    df_consolidado = []\n",
    "    for nome_modelo, df in resultados_modelos.items():\n",
    "        df_temp = df.copy()\n",
    "        df_temp[\"Modelo\"] = nome_modelo\n",
    "        df_consolidado.append(df_temp)\n",
    "    \n",
    "    df_consolidado = pd.concat(df_consolidado, ignore_index=True)\n",
    "    \n",
    "    # Reorganizar colunas\n",
    "    colunas_order = [\"Modelo\", \"Instância\", \"Classe\", \"Precisão\", \"Recall\", \"F1-Score\", \"Suporte\", \"Vértices Classe 2\"]\n",
    "    df_consolidado = df_consolidado[colunas_order]\n",
    "    \n",
    "    # Salvar\n",
    "    df_consolidado.to_csv(caminho_saida, index=False, float_format='%.2f')\n",
    "    print(f\"Resultados consolidados salvos em '{caminho_saida}'.\")\n",
    "\n",
    "# Função principal para orquestrar o fluxo\n",
    "def main():\n",
    "    # Carregar e padronizar DataFrames\n",
    "    dataframes_padronizados, todas_colunas = carregar_e_padronizar_dataframes(caminho)\n",
    "    \n",
    "    # Preparar dados de treinamento e teste\n",
    "    # Ajuste num_train conforme necessário (30 no seu exemplo)\n",
    "    X_train, y_train, test_data, colunas_vertices = preparar_dados(dataframes_padronizados, todas_colunas, num_train=150)\n",
    "    \n",
    "    # Treinar os modelos\n",
    "    scaler, pca, modelos_treinados = treinar_modelos(X_train, y_train, usar_pca=True)\n",
    "    \n",
    "    # Avaliar os modelos\n",
    "    resultados_modelos = avaliar_modelos(modelos_treinados, scaler, pca, test_data, todas_colunas, colunas_vertices)\n",
    "    \n",
    "    # Salvar resultados individuais\n",
    "    salvar_resultados(resultados_modelos)\n",
    "    \n",
    "    # Opcional: Salvar resultados consolidados\n",
    "    salvar_resultados_consolidados(resultados_modelos, caminho_saida=\"../Main/Resultados Modelos Matriz/resultados_consolidados.csv\")\n",
    "    \n",
    "    # Exibir as primeiras linhas dos DataFrames de resultados\n",
    "    for nome_modelo, df in resultados_modelos.items():\n",
    "        print(f\"\\nResultados do modelo: {nome_modelo}\")\n",
    "        print(df.head())\n",
    "\n",
    "# Executar a função principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído. Resultados salvos em '../Main/Resultados Modelos Matriz/resultados_processados.csv'.\n",
      "           Instância        Modelo Valor da Diversidade Máxima  \\\n",
      "0  MDG-a_15_n500_m50  RandomForest                     6132.81   \n",
      "1  MDG-a_16_n500_m50  RandomForest                     6409.65   \n",
      "2  MDG-a_17_n500_m50  RandomForest                     6460.24   \n",
      "3  MDG-a_18_n500_m50  RandomForest                     6463.02   \n",
      "4  MDG-a_19_n500_m50  RandomForest                     6224.35   \n",
      "\n",
      "                               Vértices Selecionados  \n",
      "0  [1, 6, 38, 43, 63, 67, 74, 75, 122, 125, 130, ...  \n",
      "1  [1, 9, 15, 18, 42, 44, 51, 67, 71, 78, 97, 108...  \n",
      "2  [17, 24, 30, 40, 46, 71, 82, 95, 122, 144, 148...  \n",
      "3  [6, 63, 67, 68, 91, 93, 104, 106, 108, 113, 12...  \n",
      "4  [7, 13, 29, 35, 39, 44, 53, 66, 72, 75, 79, 89...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def main():\n",
    "    # Caminhos\n",
    "    csv_input_path = \"../Main/Resultados Modelos Matriz/resultados_consolidados.csv\"  # Caminho para o CSV de entrada\n",
    "    txt_folder = \"../Instances\"  # Caminho para a pasta contendo os arquivos .txt\n",
    "    csv_output_path = \"../Main/Resultados Modelos Matriz/resultados_processados.csv\"  # Caminho para o CSV de saída\n",
    "\n",
    "    # Verificações Iniciais\n",
    "    if not os.path.exists(csv_input_path):\n",
    "        raise FileNotFoundError(f\"O arquivo CSV de entrada '{csv_input_path}' não foi encontrado.\")\n",
    "    \n",
    "    if not os.path.isdir(txt_folder):\n",
    "        raise NotADirectoryError(f\"A pasta '{txt_folder}' não foi encontrada ou não é um diretório.\")\n",
    "    \n",
    "    # Ler o arquivo CSV de entrada\n",
    "    df = pd.read_csv(csv_input_path)\n",
    "\n",
    "    # Verificar se as colunas necessárias existem\n",
    "    colunas_necessarias = [\"Instância\", \"Modelo\", \"Classe\", \"Vértices Classe 2\"]\n",
    "    for coluna in colunas_necessarias:\n",
    "        if coluna not in df.columns:\n",
    "            raise ValueError(f\"A coluna '{coluna}' não foi encontrada no CSV de entrada.\")\n",
    "\n",
    "    # Filtrar apenas as linhas onde a Classe é 2\n",
    "    df_classe2 = df[df[\"Classe\"] == 2].copy()\n",
    "\n",
    "    # Função para parsear a string de lista de vértices\n",
    "    def parse_vertices(vertices_str):\n",
    "        \"\"\"\n",
    "        Converte uma string representando uma lista de vértices em uma lista real.\n",
    "        \n",
    "        Args:\n",
    "            vertices_str (str): String no formato \"[v1, v2, ...]\".\n",
    "        \n",
    "        Returns:\n",
    "            list: Lista de vértices como strings.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Utilizar ast.literal_eval para converter a string em uma lista\n",
    "            vertices = ast.literal_eval(vertices_str)\n",
    "            # Garantir que todos os vértices sejam strings\n",
    "            return [str(v) for v in vertices]\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Erro ao parsear vértices: '{vertices_str}' - {e}\")\n",
    "            return []\n",
    "\n",
    "    # Função para extrair o nome base do arquivo .txt\n",
    "    def extrair_nome_base(instancia):\n",
    "        \"\"\"\n",
    "        Extrai a parte do nome da instância que corresponde ao nome do arquivo .txt.\n",
    "        \n",
    "        Exemplo:\n",
    "            'GKD-a_4_n10_m2_matriz_adjacencia_caracteristicas' -> 'GKD-a_4_n10_m2'\n",
    "        \n",
    "        Args:\n",
    "            instancia (str): Nome completo da instância.\n",
    "        \n",
    "        Returns:\n",
    "            str: Nome base correspondente ao arquivo .txt.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Supondo que a parte relevante termina antes de '_matriz_adjacencia_caracteristicas'\n",
    "            nome_base = instancia.split('_matriz_adjacencia_caracteristicas')[0]\n",
    "            return nome_base\n",
    "        except IndexError:\n",
    "            print(f\"Erro ao extrair nome base da instância '{instancia}'.\")\n",
    "            return instancia  # Retorna o nome completo se o padrão não for encontrado\n",
    "\n",
    "    # Inicializar listas para armazenar os resultados\n",
    "    instancias_final = []\n",
    "    modelos_final = []\n",
    "    diversidade_maxima_final = []\n",
    "    vertices_selecionados_final = []\n",
    "\n",
    "    # Iterar sobre as linhas filtradas (Classe=2)\n",
    "    for index, row in df_classe2.iterrows():\n",
    "        instancia_completa = row[\"Instância\"]\n",
    "        modelo = row[\"Modelo\"]\n",
    "        vertices_str = row[\"Vértices Classe 2\"]\n",
    "        vertices = parse_vertices(vertices_str)\n",
    "        \n",
    "        # Extrair o nome base para construir o nome do arquivo .txt\n",
    "        nome_base = extrair_nome_base(instancia_completa)\n",
    "        \n",
    "        if not vertices:\n",
    "            # Se não houver vértices, atribuir 0.00 como diversidade máxima\n",
    "            instancias_final.append(nome_base)\n",
    "            modelos_final.append(modelo)\n",
    "            diversidade_maxima_final.append(0.00)\n",
    "            vertices_selecionados_final.append(vertices_str)\n",
    "            continue\n",
    "        \n",
    "        txt_filename = f\"{nome_base}.txt\"\n",
    "        txt_path = os.path.join(txt_folder, txt_filename)\n",
    "        \n",
    "        if not os.path.exists(txt_path):\n",
    "            print(f\"Arquivo .txt não encontrado para a instância '{instancia_completa}': {txt_path}\")\n",
    "            instancias_final.append(nome_base)\n",
    "            modelos_final.append(modelo)\n",
    "            diversidade_maxima_final.append(0.00)\n",
    "            vertices_selecionados_final.append(vertices_str)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Ler o arquivo .txt como DataFrame\n",
    "            # Ajuste o parâmetro 'sep' conforme o delimitador usado nos seus arquivos .txt\n",
    "            # Aqui, assumo que o delimitador é espaço\n",
    "            df_adjacencia = pd.read_csv(txt_path, sep=\" \", header=None, skiprows=1, names=['V1', 'V2', 'Peso'])\n",
    "            \n",
    "            # Filtrar apenas as arestas onde ambos os vértices estão na lista selecionada\n",
    "            df_filtrado = df_adjacencia[\n",
    "                df_adjacencia['V1'].astype(str).isin(vertices) &\n",
    "                df_adjacencia['V2'].astype(str).isin(vertices)\n",
    "            ]\n",
    "            \n",
    "            # Calcular a soma dos pesos dessas arestas\n",
    "            soma = df_filtrado['Peso'].sum()\n",
    "            \n",
    "            # Arredondar a soma para duas casas decimais\n",
    "            soma_formatada = round(soma, 2)\n",
    "            \n",
    "            # Adicionar os resultados às listas finais\n",
    "            instancias_final.append(nome_base)\n",
    "            modelos_final.append(modelo)\n",
    "            diversidade_maxima_final.append(soma_formatada)\n",
    "            vertices_selecionados_final.append(vertices_str)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo '{txt_filename}': {e}\")\n",
    "            instancias_final.append(nome_base)\n",
    "            modelos_final.append(modelo)\n",
    "            diversidade_maxima_final.append(0.00)\n",
    "            vertices_selecionados_final.append(vertices_str)\n",
    "\n",
    "    # Criar um novo DataFrame com os resultados\n",
    "    df_final = pd.DataFrame({\n",
    "        \"Instância\": instancias_final,\n",
    "        \"Modelo\": modelos_final,\n",
    "        \"Valor da Diversidade Máxima\": diversidade_maxima_final,\n",
    "        \"Vértices Selecionados\": vertices_selecionados_final\n",
    "    })\n",
    "\n",
    "    # Formatar a coluna 'Valor da Diversidade Máxima' para ter exatamente duas casas decimais\n",
    "    df_final[\"Valor da Diversidade Máxima\"] = df_final[\"Valor da Diversidade Máxima\"].map(\"{:.2f}\".format)\n",
    "\n",
    "    # Salvar o DataFrame final em um novo arquivo CSV\n",
    "    df_final.to_csv(csv_output_path, index=False)\n",
    "\n",
    "    print(f\"Processamento concluído. Resultados salvos em '{csv_output_path}'.\")\n",
    "    print(df_final.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas no CSV Ideal:\n",
      "['Instância', 'Valor da Diversidade Máxima', 'Vértices Selecionados']\n",
      "\n",
      "Colunas no CSV de Resultados:\n",
      "['Instância', 'Modelo', 'Valor da Diversidade Máxima', 'Vértices Selecionados']\n",
      "\n",
      "Amostra do CSV Ideal Filtrado:\n",
      "         Instância  Valor_Otimo\n",
      "0  GKD-a_10_n10_m3    435.71251\n",
      "1  GKD-a_11_n10_m4    649.72168\n",
      "2  GKD-a_12_n10_m4   1181.47302\n",
      "3  GKD-a_13_n10_m4    733.43340\n",
      "4  GKD-a_14_n10_m4    999.46989\n",
      "\n",
      "Amostra do CSV de Resultados Filtrado:\n",
      "                        Instância        Modelo  Valor_Resultado  \\\n",
      "0  GKD-a_5_n10_m2_caracteristicas  RandomForest              0.0   \n",
      "1  GKD-a_6_n10_m3_caracteristicas  RandomForest              0.0   \n",
      "2  GKD-a_7_n10_m3_caracteristicas  RandomForest              0.0   \n",
      "3  GKD-a_8_n10_m3_caracteristicas  RandomForest              0.0   \n",
      "4  GKD-a_9_n10_m3_caracteristicas  RandomForest              0.0   \n",
      "\n",
      "  Vértices Selecionados  \n",
      "0                [8, 9]  \n",
      "1             [0, 7, 9]  \n",
      "2             [2, 6, 9]  \n",
      "3             [2, 3, 5]  \n",
      "4             [0, 4, 6]  \n",
      "\n",
      "Comparação concluída. Arquivo de saída salvo em '../Main/Resultados Modelos Matriz/comparacao_multiplos_modelos.csv'.\n",
      "\n",
      "Exemplo das primeiras linhas do arquivo de saída:\n",
      "Empty DataFrame\n",
      "Columns: [Instância, Modelo, Valor_Otimo, Valor_Resultado, Proximidade (%), Vértices Selecionados]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def comparar_diversidade_maxima(csv_ideal_path, csv_resultados_path, csv_saida_path):\n",
    "    \"\"\"\n",
    "    Compara os valores de Diversidade Máxima entre dois arquivos CSV e calcula a proximidade em porcentagem.\n",
    "\n",
    "    Args:\n",
    "        csv_ideal_path (str): Caminho para o arquivo CSV com valores ótimos.\n",
    "        csv_resultados_path (str): Caminho para o arquivo CSV com valores obtidos.\n",
    "        csv_saida_path (str): Caminho para salvar o arquivo CSV de saída.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verificar se os arquivos CSV de entrada existem\n",
    "    if not os.path.exists(csv_ideal_path):\n",
    "        raise FileNotFoundError(f\"O arquivo CSV ideal '{csv_ideal_path}' não foi encontrado.\")\n",
    "    if not os.path.exists(csv_resultados_path):\n",
    "        raise FileNotFoundError(f\"O arquivo CSV de resultados '{csv_resultados_path}' não foi encontrado.\")\n",
    "    \n",
    "    # Ler os arquivos CSV\n",
    "    try:\n",
    "        df_ideal = pd.read_csv(csv_ideal_path, sep=\",\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erro ao ler o CSV ideal: {e}\")\n",
    "    \n",
    "    try:\n",
    "        df_resultados = pd.read_csv(csv_resultados_path, sep=\",\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erro ao ler o CSV de resultados: {e}\")\n",
    "    \n",
    "    # Remover espaços em branco dos nomes das colunas\n",
    "    df_ideal.columns = df_ideal.columns.str.strip()\n",
    "    df_resultados.columns = df_resultados.columns.str.strip()\n",
    "    \n",
    "    # Imprimir os nomes das colunas para depuração\n",
    "    print(\"Colunas no CSV Ideal:\")\n",
    "    print(df_ideal.columns.tolist())\n",
    "    print(\"\\nColunas no CSV de Resultados:\")\n",
    "    print(df_resultados.columns.tolist())\n",
    "    \n",
    "    # Verificar se as colunas necessárias existem\n",
    "    colunas_necessarias_ideal = [\"Instância\", \"Valor da Diversidade Máxima\"]\n",
    "    for coluna in colunas_necessarias_ideal:\n",
    "        if coluna not in df_ideal.columns:\n",
    "            raise ValueError(f\"A coluna '{coluna}' não foi encontrada no CSV ideal.\")\n",
    "    \n",
    "    colunas_necessarias_resultados = [\"Instância\", \"Modelo\", \"Valor da Diversidade Máxima\", \"Vértices Selecionados\"]\n",
    "    for coluna in colunas_necessarias_resultados:\n",
    "        if coluna not in df_resultados.columns:\n",
    "            raise ValueError(f\"A coluna '{coluna}' não foi encontrada no CSV de resultados.\")\n",
    "    \n",
    "    # Selecionar apenas as colunas necessárias\n",
    "    df_ideal_subset = df_ideal[['Instância', 'Valor da Diversidade Máxima']].copy()\n",
    "    df_resultados_subset = df_resultados[['Instância', 'Modelo', 'Valor da Diversidade Máxima', 'Vértices Selecionados']].copy()\n",
    "    \n",
    "    # Renomear as colunas para evitar confusão após o merge\n",
    "    df_ideal_subset.rename(columns={'Valor da Diversidade Máxima': 'Valor_Otimo'}, inplace=True)\n",
    "    df_resultados_subset.rename(columns={'Valor da Diversidade Máxima': 'Valor_Resultado'}, inplace=True)\n",
    "    \n",
    "    # Converter os valores para numéricos (caso estejam como strings)\n",
    "    df_ideal_subset['Valor_Otimo'] = pd.to_numeric(df_ideal_subset['Valor_Otimo'], errors='coerce')\n",
    "    df_resultados_subset['Valor_Resultado'] = pd.to_numeric(df_resultados_subset['Valor_Resultado'], errors='coerce')\n",
    "    \n",
    "    # Verificar se há valores NaN após a conversão\n",
    "    if df_ideal_subset['Valor_Otimo'].isnull().any():\n",
    "        print(\"Atenção: Existem valores NaN em 'Valor_Otimo'.\")\n",
    "    if df_resultados_subset['Valor_Resultado'].isnull().any():\n",
    "        print(\"Atenção: Existem valores NaN em 'Valor_Resultado'.\")\n",
    "    \n",
    "    # Imprimir uma amostra dos dados filtrados\n",
    "    print(\"\\nAmostra do CSV Ideal Filtrado:\")\n",
    "    print(df_ideal_subset.head())\n",
    "    \n",
    "    print(\"\\nAmostra do CSV de Resultados Filtrado:\")\n",
    "    print(df_resultados_subset.head())\n",
    "    \n",
    "    # Merge dos DataFrames com base na coluna 'Instância'\n",
    "    df_comparacao = pd.merge(df_ideal_subset, df_resultados_subset, on='Instância', how='inner')\n",
    "    \n",
    "    # Calcular a Proximidade (%) \n",
    "    # Fórmula: (Valor_Resultado / Valor_Otimo) * 100\n",
    "    # Se Valor_Otimo for 0, definir Proximidade como 0 para evitar divisão por zero\n",
    "    df_comparacao['Proximidade (%)'] = df_comparacao.apply(\n",
    "        lambda row: (row['Valor_Resultado'] / row['Valor_Otimo'] * 100) if row['Valor_Otimo'] != 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Arredondar os valores para duas casas decimais\n",
    "    df_comparacao['Valor_Otimo'] = df_comparacao['Valor_Otimo'].round(2)\n",
    "    df_comparacao['Valor_Resultado'] = df_comparacao['Valor_Resultado'].round(2)\n",
    "    df_comparacao['Proximidade (%)'] = df_comparacao['Proximidade (%)'].round(2)\n",
    "    \n",
    "    # Reorganizar as colunas conforme solicitado\n",
    "    df_final = df_comparacao[['Instância', 'Modelo', 'Valor_Otimo', 'Valor_Resultado', 'Proximidade (%)', 'Vértices Selecionados']].copy()\n",
    "    \n",
    "    # Salvar o DataFrame final em um novo arquivo CSV\n",
    "    df_final.to_csv(csv_saida_path, index=False, float_format='%.2f')\n",
    "    \n",
    "    print(f\"\\nComparação concluída. Arquivo de saída salvo em '{csv_saida_path}'.\")\n",
    "    print(\"\\nExemplo das primeiras linhas do arquivo de saída:\")\n",
    "    print(df_final.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Defina os caminhos para os arquivos CSV\n",
    "    csv_ideal = \"../Great values/great_values.csv\"                     # Substitua pelo caminho real do seu CSV ideal\n",
    "    csv_resultados = \"../Main/Resultados Modelos Matriz/resultados_processados.csv\"   # Substitua pelo caminho real do seu CSV de resultados\n",
    "    csv_saida = \"../Main/Resultados Modelos Matriz/comparacao_multiplos_modelos.csv\"  # Nome do arquivo de saída\n",
    "    \n",
    "    # Chamar a função de comparação\n",
    "    comparar_diversidade_maxima(csv_ideal, csv_resultados, csv_saida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráficos de barras por instância salvos em 'graficos_resultados'.\n",
      "Gráfico de proximidade média por modelo salvo em 'graficos_resultados'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinic\\AppData\\Local\\Temp\\ipykernel_8108\\659334930.py:63: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot de proximidade por modelo salvo em 'graficos_resultados'.\n",
      "Heatmap de proximidade salvo em 'graficos_resultados'.\n",
      "Gráfico de linha de proximidade por modelo salvo em 'graficos_resultados'.\n",
      "Scatter plot de Valor Ótimo vs Valor Resultado salvo em 'graficos_resultados'.\n",
      "Histograma de distribuição de proximidade por modelo salvo em 'graficos_resultados'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Configurações de estilo para os gráficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "def gerar_graficos(csv_path, output_folder):\n",
    "    \"\"\"\n",
    "    Gera gráficos de visualização a partir do CSV de comparação.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Caminho para o arquivo CSV de comparação.\n",
    "        output_folder (str): Pasta onde os gráficos serão salvos.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ler o arquivo CSV\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erro ao ler o CSV de comparação: {e}\")\n",
    "\n",
    "    # Verificar se as colunas necessárias existem\n",
    "    colunas_necessarias = [\"Instância\", \"Modelo\", \"Valor_Otimo\", \"Valor_Resultado\", \"Proximidade (%)\", \"Vértices Selecionados\"]\n",
    "    for coluna in colunas_necessarias:\n",
    "        if coluna not in df.columns:\n",
    "            raise ValueError(f\"A coluna '{coluna}' não foi encontrada no CSV de comparação.\")\n",
    "\n",
    "    # Criar a pasta de saída se não existir\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 1. Gráfico de Barras por Instância\n",
    "    instancias = df['Instância'].unique()\n",
    "    for instancia in instancias:\n",
    "        df_instancia = df[df['Instância'] == instancia]\n",
    "        modelos = df_instancia['Modelo']\n",
    "        valores_otimos = df_instancia['Valor_Otimo']\n",
    "        valores_resultados = df_instancia['Valor_Resultado']\n",
    "\n",
    "        x = range(len(modelos))\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(x, valores_otimos, width=0.4, label='Valor Ótimo', align='center')\n",
    "        plt.bar(x, valores_resultados, width=0.4, label='Valor Resultado', align='edge')\n",
    "        plt.xlabel('Modelo')\n",
    "        plt.ylabel('Valor da Diversidade Máxima')\n",
    "        plt.title(f'Comparação de Diversidade Máxima para {instancia}')\n",
    "        plt.xticks(x, modelos, rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Salvar o gráfico\n",
    "        plt.savefig(os.path.join(output_folder, f'barra_{instancia}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Gráficos de barras por instância salvos em '{output_folder}'.\")\n",
    "\n",
    "    # 2. Gráfico de Proximidade (%) por Modelo\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(\n",
    "        x='Modelo',\n",
    "        y='Proximidade (%)',\n",
    "        data=df,\n",
    "        errorbar=None,  # Substitui ci=None\n",
    "        palette='viridis',\n",
    "        estimator=lambda x: sum(x)/len(x)\n",
    "    )\n",
    "    plt.xlabel('Modelo')\n",
    "    plt.ylabel('Proximidade Média (%)')\n",
    "    plt.title('Proximidade Média (%) por Modelo')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'proximidade_media_por_modelo.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Gráfico de proximidade média por modelo salvo em '{output_folder}'.\")\n",
    "\n",
    "    # 3. Boxplot de Proximidade (%) por Modelo\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(\n",
    "        x='Modelo',\n",
    "        y='Proximidade (%)',\n",
    "        data=df,\n",
    "        hue='Modelo',  # Adiciona hue para evitar o FutureWarning\n",
    "        palette='Set2'\n",
    "    )\n",
    "    plt.xlabel('Modelo')\n",
    "    plt.ylabel('Proximidade (%)')\n",
    "    plt.title('Distribuição da Proximidade (%) por Modelo')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend([],[], frameon=False)  # Remove a legenda duplicada\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'boxplot_proximidade_por_modelo.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Boxplot de proximidade por modelo salvo em '{output_folder}'.\")\n",
    "\n",
    "    # 4. Heatmap de Proximidade (%) por Instância e Modelo\n",
    "    heatmap_data = df.pivot(index=\"Instância\", columns=\"Modelo\", values=\"Proximidade (%)\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "    plt.xlabel('Modelo')\n",
    "    plt.ylabel('Instância')\n",
    "    plt.title('Heatmap da Proximidade (%) por Instância e Modelo')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'heatmap_proximidade.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Heatmap de proximidade salvo em '{output_folder}'.\")\n",
    "\n",
    "    # 5. Gráfico de Linha de Proximidade por Modelo\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for modelo in df['Modelo'].unique():\n",
    "        df_modelo = df[df['Modelo'] == modelo]\n",
    "        plt.plot(df_modelo['Instância'], df_modelo['Proximidade (%)'], marker='o', label=modelo)\n",
    "    \n",
    "    plt.xlabel('Instância')\n",
    "    plt.ylabel('Proximidade (%)')\n",
    "    plt.title('Proximidade (%) por Instância e Modelo')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'linha_proximidade_por_modelo.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Gráfico de linha de proximidade por modelo salvo em '{output_folder}'.\")\n",
    "\n",
    "    # 6. Scatter Plot: Valor Ótimo vs Valor Resultado, colorido por Modelo\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(x='Valor_Otimo', y='Valor_Resultado', hue='Modelo', data=df, palette='deep')\n",
    "    plt.plot(\n",
    "        [df['Valor_Otimo'].min(), df['Valor_Otimo'].max()],\n",
    "        [df['Valor_Otimo'].min(), df['Valor_Otimo'].max()],\n",
    "        'k--', label='Linha de Igualdade'\n",
    "    )\n",
    "    plt.xlabel('Valor Ótimo')\n",
    "    plt.ylabel('Valor Resultado')\n",
    "    plt.title('Valor Resultado vs Valor Ótimo por Modelo')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'scatter_valor_vs_otimo.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Scatter plot de Valor Ótimo vs Valor Resultado salvo em '{output_folder}'.\")\n",
    "\n",
    "    # 7. Gráfico de Distribuição de Proximidade (%) para Todos os Modelos\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.histplot(data=df, x='Proximidade (%)', hue='Modelo', kde=True, multiple='stack', palette='bright')\n",
    "    plt.xlabel('Proximidade (%)')\n",
    "    plt.ylabel('Contagem')\n",
    "    plt.title('Distribuição da Proximidade (%) por Modelo')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'distribuicao_proximidade_por_modelo.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Histograma de distribuição de proximidade por modelo salvo em '{output_folder}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Defina o caminho para o CSV gerado anteriormente\n",
    "    csv_comparacao = \"../Main/Resultados Modelos Matriz/comparacao_multiplos_modelos.csv\"  # Substitua pelo caminho correto, se necessário\n",
    "    \n",
    "    # Defina a pasta onde os gráficos serão salvos\n",
    "    pasta_saida = \"Main/Resultados Modelos Matriz\"\n",
    "\n",
    "    # Chamar a função para gerar os gráficos\n",
    "    gerar_graficos(csv_comparacao, pasta_saida)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
